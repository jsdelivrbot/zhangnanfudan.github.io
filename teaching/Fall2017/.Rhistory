source('~/Documents/zhangnanfudan.github.io/teaching/Fall2017/ch1.R')
rm(list = ls())
pi
exp(1)
log(2)
sqrt(pi)
1/sqrt(2*pi) * exp(-2)
dnorm(2)
plot(cars, xlab="Speed", ylab="Distance to Stop",
main="Stopping Distance for Cars in 1920")
seq(0, 3, 0.5)
x <- seq(0, 3, 0.5)
y = seq(0, 3, 0.5)
?Syntax
?Arithmetic
?Logic
?Comparison #relational operators
?Extract #operators on vectors and arrays
?Control #control flow
T
F
t
class(t)
g
help.search("permutation")
x = 1:6
sample(x) #permutation of all elements of x
k=3
sample(x, size=k) #permutation of k elements of x
set.seed(123)
sample(x)
sample(x, size=k)
help(density)
help(faithful)
d <- density(faithful$eruptions, bw = "sj")
d
plot(d, main="Eruption time in minutes")
data()
sumdice <- function(n) {
k <- sample(1:6, size=n, replace=TRUE)
return(sum(k))
}
sumdice(2)
a <- sumdice(100)
a / 100
sumdice <- function(n)
sum(sample(1:6, size=n, replace=TRUE))
sumdice <- function(n, sides = 6) {
if (sides < 1) return (0)
k <- sample(1:sides, size=n, replace=TRUE)
return(sum(k))
}
sumdice(5) # default 6 sides
sumdice(n=5, sides=4) # 4 sides
help("iris")
class(iris)
dim(iris)
head(iris)
names(iris)
table(iris$Species)
summary(iris$Species)
w <- iris[[2]] #Column Sepal.Width
mean(w)
w = iris$Sepal.Width
w = iris[,2] # more general, can select multiple elements
attach(iris)
summary(Petal.Length[51:100]) #versicolor petal length
detach(iris) # Good practice!
x <- 1:24 # vector
dim(x) <- length(x) # 1 dimensional array
matrix(1:24, nrow=4, ncol=6) # 4 by 6 matrix
x <- array(1:24, c(3, 4, 2)) # 3 by 4 by 2 array
x
x[, ,2]
x[,3,2]
matrix(0, nrow=2, ncol=2)
matrix(c(0, 0, 0, 0), nrow=2, ncol=2)
matrix(0, 2, 2)
matrix(1:8, nrow=2, ncol=4, byrow = FALSE)
matrix(1:8, nrow=2, ncol=4, byrow = T)
x <- as.matrix(iris[,1:4]) #all rows of columns 1 to 4
mean(x[,2]) #mean of sepal width, all species
mean(x[51:100,3]) #mean of petal length, versicolor
iris3 #50 × 4 × 3 array of iris data
?rnorm
w <- wilcox.test(rnorm(10), rnorm(10, 2))
w
w$statistic
w$p.value
a <- matrix(runif(8), 4, 2) #a 4x2 matrix
dimnames(a) <- list(NULL, c("x", "y"))
a
dimnames(a) <- list(letters[1:4], c("x", "y"))
a
row.names(a) <- list("NE", "NW", "SW", "SE")
a
rm(list = ls())
getwd()
install.packages("MASS")
library(MASS)
help(package='MASS')
install.packages("MASS")
install.packages("MASS")
pi
pi
exp(1)
log(2)
log(2)
sqrt(pi)
?dnorm
1/sqrt(2*pi) * exp(-2)
dnorm(2)
plot(cars, xlab="Speed", ylab="Distance to Stop",
main="Stopping Distance for Cars in 1920")
cars
2:10
-2:10
10:(-2)
0.1*(10:(-2))
?seq
seq(0, 3, 0.5)
x <- seq(0, 3, 0.5)
x
?Syntax
?Arithmetic
?Logic
?Comparison #relational operators
?Extract #operators on vectors and arrays
?Control #control flow
T
Tx
T
F
t
class(t)
g
help.search("permutation")
x = 1:6
rm(list = ls())
x = 1:6
sample(x) #permutation of all elements of x
k=3
sample(x, size=k) #permutation of k elements of x
sample(x, size=k) #permutation of k elements of x
sample(x, size=k) #permutation of k elements of x
set.seed(123)
sample(x)
sample(x, size=k)
set.seed(123)
sample(x)
sample(x, size=k)
help(density)
help(faithful)
faithful
d <- density(faithful$eruptions, bw = "sj")
d
plot(d, main="Eruption time in minutes")
data()
sumdice <- function(n) {
k <- sample(1:6, size=n, replace=TRUE)
return(sum(k))
}
sumdice(2)
a <- sumdice(100)
a
a / 100
a <- sumdice(10000)
a / 10000
sumdice <- function(n, sides = 6) {
if (sides < 1) return (0)
k <- sample(1:sides, size=n, replace=TRUE)
return(sum(k))
}
sumdice(5) # default 6 sides
sumdice(n=5, sides=4) # 4 sides
help("iris")
class(iris)
rm(list = ls())
class(iris)
dim(iris)
head(iris)
head(iris)
names(iris)
table(iris$Species)
summary(iris$Species)
w <- iris[[2]] #Column Sepal.Width
mean(w)
attach(iris)
summary(Petal.Length[51:100]) #versicolor petal length
detach(iris) # Good practice!
n <- 1000
k <- 0      #counter for accepted
j <- 0      #iterations
y <- numeric(n)
while (k < n) {
u <- runif(1)
j <- j + 1
x <- runif(1)  #random variate from g
if (x * (1-x) > u) {
#we accept x
k <- k + 1
y[k] <- x
}
}
j
n <- 1000
k <- 0      #counter for accepted
j <- 0      #iterations
y <- numeric(n)
while (k < n) {
u <- runif(1)
j <- j + 1
x <- runif(1)  #random variate from g
if (4*x * (1-x) > u) {
#we accept x
k <- k + 1
y[k] <- x
}
}
j
p <- seq(.1, .9, .1)
Qhat <- quantile(y, p)   #quantiles of sample
Q <- qbeta(p, 2, 2)      #theoretical quantiles
se <- sqrt(p * (1-p) / (n * dbeta(Q, 2, 2)^2)) #see Ch. 2
round(rbind(Qhat, Q, se), 3)
p <- seq(.1, .9, .1)
Qhat <- quantile(y, p)   #quantiles of sample
Q <- qbeta(p, 2, 2)      #theoretical quantiles
round(rbind(Qhat, Q), 3)
n <- 1000
a <- 3
b <- 2
u <- rgamma(n, shape=a, rate=1)
v <- rgamma(n, shape=b, rate=1)
x <- u / (u + v)
q <- qbeta(ppoints(n), a, b)
qqplot(q, x, cex=0.25, xlab="Beta(3, 2)", ylab="Sample")
abline(0, 1)
n <- 1000
nu <- 2
X <- matrix(rnorm(n*nu), n, nu)^2 #matrix of sq. normals
y <- rowSums(X)
y <- apply(X, MARGIN=1, FUN=sum)  #a vector length n
mean(y)
mean(y^2)
n <- 1000
x1 <- rgamma(n, 2, 2)
x2 <- rgamma(n, 2, 4)
s <- x1 + x2              #the convolution
u <- runif(n)
k <- as.integer(u > 0.5)  #vector of 0's and 1's
x <- k * x1 + (1-k) * x2  #the mixture
par(mfcol=c(1,2))         #two graphs per page
hist(s, prob=TRUE)
hist(x, prob=TRUE)
par(mfcol=c(1,1))         #restore display
n <- 1000
x1 <- rnorm(n, 0, 1)
x2 <- rnorm(n, 3, 1)
s <- x1 + x2              #the convolution
u <- runif(n)
k <- as.integer(u > 0.5)  #vector of 0's and 1's
x <- k * x1 + (1-k) * x2  #the mixture
par(mfcol=c(1,2))         #two graphs per page
hist(s, prob=TRUE)
hist(x, prob=TRUE)
n <- 10000
x1 <- rnorm(n, 0, 1)
x2 <- rnorm(n, 3, 1)
s <- x1 + x2              #the convolution
u <- runif(n)
k <- as.integer(u > 0.5)  #vector of 0's and 1's
x <- k * x1 + (1-k) * x2  #the mixture
par(mfcol=c(1,2))         #two graphs per page
hist(s, prob=TRUE)
hist(x, prob=TRUE)
n <- 1000
x1 <- rnorm(n, 0, 1)
x2 <- rnorm(n, 10, 1)
s <- x1 + x2              #the convolution
u <- runif(n)
k <- as.integer(u > 0.5)  #vector of 0's and 1's
x <- k * x1 + (1-k) * x2  #the mixture
par(mfcol=c(1,2))         #two graphs per page
hist(s, prob=TRUE)
hist(x, prob=TRUE)
m <- 10000
x <- runif(m)
theta.hat <- mean(exp(-x))
print(theta.hat)
print(1 - exp(-1))
m <- 10000
x <- runif(m, min=2, max=4)
theta.hat <- mean(exp(-x)) * 2
print(theta.hat)
print(exp(-2) - exp(-4))
m <- 10000
x <- runif(m, min=2, max=4)
theta.hat <- mean(exp(-x)) * 2
print(theta.hat)
print(exp(-2) - exp(-4))
x <- seq(.1, 2.5, length = 10)
m <- 10000
u <- runif(m)
cdf <- numeric(length(x))
for (i in 1:length(x)) {
g <- x[i] * exp(-(u * x[i])^2 / 2)
cdf[i] <- mean(g) / sqrt(2 * pi) + 0.5
}
Phi <- pnorm(x)
print(round(rbind(x, cdf, Phi), 3))
x <- seq(.1, 2.5, length = 10)
m <- 10000
z <- rnorm(m)
dim(x) <- length(x)
p <- apply(x, MARGIN = 1,
FUN = function(x, z) {mean(z < x)}, z = z)
Phi <- pnorm(x)
print(round(rbind(x, p, Phi), 3))
x <- 2
m <- 10000
z <- rnorm(m)
g <- (z < x)  #the indicator function
v <- mean((g - mean(g))^2) / m
cdf <- mean(g)
c(cdf, v)
c(cdf - 1.96 * sqrt(v), cdf + 1.96 * sqrt(v))
n <- 1000
k <- 0      #counter for accepted
j <- 0      #iterations
y <- numeric(n)
while (k < n) {
u <- runif(1)
j <- j + 1
x <- runif(1)  #random variate from g
if (x * (1-x) > u) {
#we accept x
k <- k + 1
y[k] <- x
}
}
j
n <- 1000
k <- 0      #counter for accepted
j <- 0      #iterations
y <- numeric(n)
while (k < n) {
u <- runif(1)
j <- j + 1
x <- runif(1)  #random variate from g
if (4*x * (1-x) > u) {
#we accept x
k <- k + 1
y[k] <- x
}
}
j
p <- seq(.1, .9, .1)
Qhat <- quantile(y, p)   #quantiles of sample
Q <- qbeta(p, 2, 2)      #theoretical quantiles
round(rbind(Qhat, Q), 3)
p <- seq(.1, .9, .1)
Qhat <- quantile(y, p)   #quantiles of sample
Q <- qbeta(p, 2, 2)      #theoretical quantiles
round(rbind(Qhat, Q), 3)
n <- 1000
a <- 3
b <- 2
u <- rgamma(n, shape=a, rate=1)
v <- rgamma(n, shape=b, rate=1)
x <- u / (u + v)
q <- qbeta(ppoints(n), a, b)
qqplot(q, x, cex=0.25, xlab="Beta(3, 2)", ylab="Sample")
abline(0, 1)
n <- 1000
nu <- 2
y <- rowSums(X)
head(y)
y
?apply
y <- apply(X, MARGIN=1, FUN=sum)  #a vector length n
y <- rowSums(X)
y <- apply(X, MARGIN=1, FUN=sum)  #a vector length n
mean(y)
n <- 1000
x1 <- rnorm(n, 0, 1)
x2 <- rnorm(n, 10, 1)
s <- x1 + x2              #the convolution
u <- runif(n)
k <- as.integer(u > 0.5)  #vector of 0's and 1's
x <- k * x1 + (1-k) * x2  #the mixture
par(mfcol=c(1,2))         #two graphs per page
hist(s, prob=TRUE)
hist(x, prob=TRUE)
par(mfcol=c(1,1))         #restore display
mu <- c(0, 0)
Sigma <- matrix(c(1, .9, .9, 1), nrow = 2, ncol = 2)
mu <- c(0, 0)
Sigma <- matrix(c(1, .9, .9, 1), nrow = 2, ncol = 2)
rmvn.eigen <-
function(n, mu, Sigma) {
# generate n random vectors from MVN(mu, Sigma)
# dimension is inferred from mu and Sigma
d <- length(mu)
ev <- eigen(Sigma, symmetric = TRUE)
lambda <- ev$values
V <- ev$vectors
R <- V %*% diag(sqrt(lambda)) %*% t(V)
Z <- matrix(rnorm(n*d), nrow = n, ncol = d)
X <- Z %*% R + matrix(mu, n, d, byrow = TRUE)
X
}
X <- rmvn.eigen(1000, mu, Sigma)
plot(X, xlab = "x", ylab = "y", pch = 20)
plot(X, xlab = "x", ylab = "y", pch = 20)
print(colMeans(X))
print(cor(X))
m <- 10000
m <- 10000
x <- runif(m)
theta.hat <- mean(exp(-x))
print(theta.hat)
print(1 - exp(-1))
m <- 10000
x <- runif(m, min=2, max=4)
theta.hat <- mean(exp(-x)) * 2
print(theta.hat)
print(exp(-2) - exp(-4))
x <- seq(.1, 2.5, length = 10)
m <- 10000
u <- runif(m)
cdf <- numeric(length(x))
for (i in 1:length(x)) {
g <- x[i] * exp(-(u * x[i])^2 / 2)
cdf[i] <- mean(g) / sqrt(2 * pi) + 0.5
}
Phi <- pnorm(x)
print(round(rbind(x, cdf, Phi), 3))
print(round(rbind(x, cdf, Phi), 3))
x <- seq(.1, 2.5, length = 10)
m <- 10000
z <- rnorm(m)
dim(x) <- length(x)
p <- apply(x, MARGIN = 1,
FUN = function(x, z) {mean(z < x)}, z = z)
Phi <- pnorm(x)
print(round(rbind(x, p, Phi), 3))
Phi <- pnorm(x)
print(round(rbind(x, p, Phi), 3))
